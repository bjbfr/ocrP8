{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Documentations\n\n## TPUs\nhttps://www.tensorflow.org/guide/tpu\nhttps://cloud.google.com/tpu/docs/intro-to-tpu\nhttps://cloud.google.com/tpu/docs/system-architecture-tpu-vm\n\n## Data augmentation\nhttps://neovision.fr/data-augmentation-solutions-manque-donnees/\n\n## Modèles utilisés\nDenset net\nhttps://keras.io/api/applications/densenet/#densenet201-function\nhttps://arxiv.org/abs/1608.06993\n\nEfficient Net\nhttps://keras.io/api/applications/efficientnet/#efficientnetb4-function\nhttps://arxiv.org/abs/1905.11946\n","metadata":{}},{"cell_type":"code","source":"# These are some basic packages\nimport random, re, math, os, functools, itertools,collections\n\n# ML packages\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n# These are performance metrics\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n# This for class weights\nfrom  sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\n\nfrom kaggle_datasets import KaggleDatasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-07-26T17:30:22.264477Z","iopub.execute_input":"2022-07-26T17:30:22.264846Z","iopub.status.idle":"2022-07-26T17:30:30.527839Z","shell.execute_reply.started":"2022-07-26T17:30:22.264758Z","shell.execute_reply":"2022-07-26T17:30:30.526861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Detect the hardware and tell the appropriate distribution strategy","metadata":{}},{"cell_type":"code","source":"# Make the system tune the number of threads for us\nAUTO = tf.data.experimental.AUTOTUNE\n\nINTER_THREADS_NB = None\nINTRA_THREADS_NB = None\n\n# TF2.X runs eagerly by default\nFORCE_MODE  = False\nRUN_EAGERLY = False\n\n# Logical GPU memory limit \nLGPU_MEMORY_LIMIT = 7*1024\nlogical_gpu_name = lambda i: f\"/device:GPU:{i}\"\n\n# Add more mixed precision and/or XLA to allow the TPU memory to handle larger batch sizes \n# and can speed up the training process\nMIXED_PRECISION = False\nXLA_ACCELERATE = False\n\nPREFETCH_SIZE = AUTO\nSHUFFLE_SIZE  = 2048\n\n# Detect hardware\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU: ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nSTRATEGY = None    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = 16 * STRATEGY.num_replicas_in_sync\nelse:\n    try:\n        gpus = tf.config.list_physical_devices('GPU')\n    except ValueError:\n        gpus = None\n    if gpus:\n        BATCH_SIZE = 8\n        SHUFFLE_SIZE  = None\n        PREFETCH_SIZE = 16\n        try:\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            \n            #create logical GPUs    \n            tf.config.set_logical_device_configuration(\n                    gpus[0],\n                    [\n                       tf.config.LogicalDeviceConfiguration(memory_limit=LGPU_MEMORY_LIMIT),\n                       tf.config.LogicalDeviceConfiguration(memory_limit=LGPU_MEMORY_LIMIT)\n                    ]\n                )\n            \n            #define stategy\n            lgpus = tf.config.list_logical_devices('GPU')\n            STRATEGY = tf.distribute.MirroredStrategy(devices=list( map(\n                                                                        logical_gpu_name,\n                                                                        range(len(lgpus))\n                                                                       )\n                                                                  )\n                                                     )\n            \n            print( f\"Physical GPUs: {gpus} - Logical GPUs : {lgpus}\")\n        \n        except RuntimeError as e:\n            print(e)\n            \n    else:\n        STRATEGY = tf.distribute.get_strategy()\n        BATCH_SIZE = 32\n        \n    # run tf functions eagerly\n    if FORCE_MODE:\n        tf.config.run_functions_eagerly(RUN_EAGERLY)\n        print(f\"Eager mode forced to {RUN_EAGERLY}\")\n\n    #interop threads (to run different graph)\n    if INTER_THREADS_NB is not None:\n        tf.config.threading.set_inter_op_parallelism_threads(INTER_THREADS_NB)\n        print(f\"Inter-op threads set to {INTER_THREADS_NB}\")\n\n    #intraop threads (to run within a graph)\n    if INTRA_THREADS_NB is not None:\n        tf.config.threading.set_intra_op_parallelism_threads(INTRA_THREADS_NB)\n        print(f\"Intra-op threads set to {INTRA_THREADS_NB}\")\n        \nprint(\"REPLICAS: \", STRATEGY.num_replicas_in_sync)\n\n# mixed precision\nif MIXED_PRECISION :\n    if tpu: precision = 'mixed_bfloat16'\n    else: precision = 'mixed_float16'\n    policy = tf.keras.mixed_precision.experimental.Policy(precision)\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n    print(f'Mixed precision enabled: {precision}')\n\n# xla accelerate    \nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\n    \n# Configuration for image size, training epoch, batch size, and random seed\nIMAGE_SIZE = [512, 512]\nEPOCHS = 100\nSEED = 100\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:30.529905Z","iopub.execute_input":"2022-07-26T17:30:30.530165Z","iopub.status.idle":"2022-07-26T17:30:36.431120Z","shell.execute_reply.started":"2022-07-26T17:30:30.530138Z","shell.execute_reply":"2022-07-26T17:30:36.430139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set the data access","metadata":{}},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\n# These are available image sizes in the data set\nGCS_PATH_SELECT = { \n    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n}\nGCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\nTRAINING_FILENAMES   = lambda img_size=IMAGE_SIZE[0]: tf.io.gfile.glob(GCS_PATH_SELECT[img_size] + '/train/*.tfrec')\nVALIDATION_FILENAMES = lambda img_size=IMAGE_SIZE[0]: tf.io.gfile.glob(GCS_PATH_SELECT[img_size] + '/val/*.tfrec')\nTEST_FILENAMES       = lambda img_size=IMAGE_SIZE[0]: tf.io.gfile.glob(GCS_PATH_SELECT[img_size] + '/test/*.tfrec')","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:36.432817Z","iopub.execute_input":"2022-07-26T17:30:36.433074Z","iopub.status.idle":"2022-07-26T17:30:37.074753Z","shell.execute_reply.started":"2022-07-26T17:30:36.433043Z","shell.execute_reply":"2022-07-26T17:30:37.073354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set  functions to \n- decode image\n- read labeled tfrec files (i.e. training & validation set) \n- unlabeled tfrec files (i.e. test set) \n- load image data","metadata":{}},{"cell_type":"code","source":"def decode_image(image_data,img_size):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.reshape(image, [img_size,img_size, 3])\n    return image\n\ndef read_labeled_tfrecord(example,img_size):\n    \n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'],img_size)\n    label = tf.cast(example['class'], tf.int32)\n    \n    return image, label\n\n# This is for data visualization\ndef read_labeled_id_tfrecord(example,img_size):\n    \n    LABELED_ID_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),\n        \"id\": tf.io.FixedLenFeature([],tf.string),\n    }\n    example = tf.io.parse_single_example(example, LABELED_ID_TFREC_FORMAT)\n    image = decode_image(example['image'],img_size)\n    label = tf.cast(example['class'], tf.int32)\n    idnum =  example['id']\n    \n    return image, label, idnum\n\ndef read_unlabeled_tfrecord(example,img_size):\n    \n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'],img_size)\n    idnum = example['id']\n    \n    return image, idnum\n\n# For best performance, read from multiple tfrec files at once\n# Disregard data's order, since data will be shuffled\ndef load_dataset(filenames,img_size, labeled = True, with_id = False,ordered = False):\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False  # Disable order to increase running speed\n    # Automatically interleaves reading\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n    # Use data in the shuffled order\n    dataset = dataset.with_options(ignore_order)\n    \n    # Returns a dataset of (image, label) pairs if labeled = True (i.e. training & validation set)\n    # or (image, id) pair if labeld = False (i.e. test set)\n    if labeled == True:\n        tfrecord_reader = functools.partial(read_labeled_tfrecord,img_size=img_size)\n        if with_id == True:\n            tfrecord_reader = functools.partial(read_labeled_id_tfrecord,img_size=img_size)\n    else:\n        tfrecord_reader = functools.partial(read_unlabeled_tfrecord,img_size=img_size)\n    \n    # read tfrecord here\n    dataset = dataset.map(tfrecord_reader, num_parallel_calls=AUTO)\n    \n    return dataset\n\n# possible kwargs: labeled,ordered,with_id\ndef get_training_dataset(img_size=IMAGE_SIZE[0],**kwargs):\n    train = load_dataset(TRAINING_FILENAMES(img_size),img_size, **{**kwargs,'labeled':True} )\n    return train\n\ndef get_validation_dataset(img_size=IMAGE_SIZE[0],**kwargs):\n    validation = load_dataset(VALIDATION_FILENAMES(img_size),img_size, **{**kwargs,'labeled':True } )\n    return validation\n\ndef get_test_dataset(img_size=IMAGE_SIZE[0],**kwargs):\n    test = load_dataset(TEST_FILENAMES(img_size) ,img_size, **{**kwargs,'labeled':False })\n    return test","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.078995Z","iopub.execute_input":"2022-07-26T17:30:37.079279Z","iopub.status.idle":"2022-07-26T17:30:37.103428Z","shell.execute_reply.started":"2022-07-26T17:30:37.079250Z","shell.execute_reply":"2022-07-26T17:30:37.101836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## configuration of Under Test model","metadata":{}},{"cell_type":"code","source":"UT_MODEL      = tf.keras.applications.EfficientNetB4\nUT_PREPROCESS = lambda x,y,id: tf.image.resize_with_pad(x,380,380)\nUT_DECODER    =  tf.keras.applications.efficientnet.decode_predictions\nUT_NAME       = 'efficientnetb4'\nPRED_DS       = get_training_dataset(img_size=331,with_id=True,ordered = True)\n\ndensenet201 = \"\"\"\nUT_MODEL      = tf.keras.applications.DenseNet201\nUT_PREPROCESS = lambda x,y,id: tf.keras.applications.densenet.preprocess_input(tf.cast(x, tf.float32))\nUT_DECODER    =  tf.keras.applications.densenet.decode_predictions\nUT_NAME       = 'densenet201'\nPRED_DS       = get_training_dataset(img_size=224,with_id=True,ordered = True)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.106388Z","iopub.execute_input":"2022-07-26T17:30:37.106900Z","iopub.status.idle":"2022-07-26T17:30:37.477225Z","shell.execute_reply.started":"2022-07-26T17:30:37.106853Z","shell.execute_reply":"2022-07-26T17:30:37.476149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count the number of images","metadata":{}},{"cell_type":"code","source":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES())  # Number of images in training set\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES())  # Number of images in validation set\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES())  # Number of images in test set\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE  # Steps of each epoch\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.478413Z","iopub.execute_input":"2022-07-26T17:30:37.478648Z","iopub.status.idle":"2022-07-26T17:30:37.918150Z","shell.execute_reply.started":"2022-07-26T17:30:37.478621Z","shell.execute_reply":"2022-07-26T17:30:37.917121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define all the classes we have","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose'] \n","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.920128Z","iopub.execute_input":"2022-07-26T17:30:37.920500Z","iopub.status.idle":"2022-07-26T17:30:37.931869Z","shell.execute_reply.started":"2022-07-26T17:30:37.920458Z","shell.execute_reply":"2022-07-26T17:30:37.930850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Set some visualization functions","metadata":{}},{"cell_type":"markdown","source":"### Set training and validation curve function to show the changes in loss and accuracy","metadata":{}},{"cell_type":"code","source":"def plot_train_valid_curves(training, validation, title, subplot):\n    \n    if subplot % 10 == 1:\n        plt.subplots(figsize = (15,15), facecolor = '#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['training', 'validation.'])","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.933529Z","iopub.execute_input":"2022-07-26T17:30:37.933848Z","iopub.status.idle":"2022-07-26T17:30:37.948101Z","shell.execute_reply.started":"2022-07-26T17:30:37.933808Z","shell.execute_reply":"2022-07-26T17:30:37.947411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set a function to plot confusion matrix","metadata":{}},{"cell_type":"code","source":"def display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize = (20,20))  # Specify the size of confusion matrix\n    ax = plt.gca()\n    ax.matshow(cmat, cmap = 'Reds')  # Draw a matrix\n    ax.set_xticks(range(len(CLASSES)))  # Set the range of X coordinate according to #classes\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})  # Set the font size of X coordinate\n    # Rotate labels on X coordinate to make them look better\n    plt.setp(ax.get_xticklabels(), rotation = 45, ha = \"left\", rotation_mode = \"anchor\")\n    ax.set_yticks(range(len(CLASSES)))  # Set the range of Y coordinate according to #classes\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})  # Set the font size of Y coordinate\n    # Rotate labels on Y coordinate to make them look better\n    plt.setp(ax.get_yticklabels(), rotation = 45, ha = \"right\", rotation_mode = \"anchor\")\n    # Round F1 score, precision, and recall to the nearest fourth decimal place\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.4f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.4f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.4f} '.format(recall)\n    # Add some comments about F1 score, precision, and recall on the plot\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict = {'fontsize': 18, 'horizontalalignment': 'right', 'verticalalignment': 'top', 'color': 'Blue'})\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.949625Z","iopub.execute_input":"2022-07-26T17:30:37.949954Z","iopub.status.idle":"2022-07-26T17:30:37.966252Z","shell.execute_reply.started":"2022-07-26T17:30:37.949911Z","shell.execute_reply":"2022-07-26T17:30:37.965441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show the beautiful flowers (refer to Dimitre Oliveira)","metadata":{}},{"cell_type":"code","source":"def batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object:\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (for test data)\n    return numpy_images, numpy_labels\n\n\ndef title_from_label_and_target_(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\n\ndef display_one_flower(image, title, subplot, red = False, titlesize = 16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize = int(titlesize) if not red else int(titlesize / 1.2), color = 'red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2] + 1)\n\n\ndef display_batch_of_images(databatch, predictions = None):\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n    rows = int(math.sqrt(len(images)))\n    cols = len(images) // rows\n    #print(f\"rows: {rows} cols: {cols}\")\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot = (rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize = (FIGSIZE, FIGSIZE / cols*rows))\n    else:\n        plt.figure(figsize = (FIGSIZE / rows * cols,FIGSIZE))\n    \n    # Display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target_(predictions[i], label)\n        dynamic_titlesize = FIGSIZE * SPACING / max(rows,cols) * 40 + 3\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize = dynamic_titlesize)\n    \n    # Layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace = 0, hspace = 0)\n    else:\n        plt.subplots_adjust(wspace = SPACING, hspace = SPACING)\n    plt.show()\n\ndef title_from_label_and_target(label, correct_label):\n    label = np.argmax(label, axis = -1)\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', should be ' if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower_eval(image, title, subplot, red = False):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize = 14, color = 'red' if red else 'black')\n    return subplot + 1\n\n#def display_n_images_with_predictions(images, predictions, labels,n=10):\n#    subplot = 331\n#    plt.figure(figsize = (13,13))\n#    for i, image in enumerate(images):\n#        title, correct = title_from_label_and_target(predictions[i], labels[i])\n#        subplot = display_one_flower_eval(image, title, subplot, not correct)\n#        if i >= (n-1):\n#            break;\n#    plt.tight_layout()\n#    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n#    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.970284Z","iopub.execute_input":"2022-07-26T17:30:37.971129Z","iopub.status.idle":"2022-07-26T17:30:37.998421Z","shell.execute_reply.started":"2022-07-26T17:30:37.971086Z","shell.execute_reply":"2022-07-26T17:30:37.996870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data augmentation","metadata":{}},{"cell_type":"code","source":"ds_map_func = lambda func: lambda ds: ds.map(func,num_parallel_calls=AUTO) \n\ndata_augment_layers = tf.keras.Sequential(\n            layers = [\n                #tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.2,fill_mode='nearest', dtype=\"float32\"),\n                tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2,width_factor=0.2,fill_mode='nearest',dtype=\"float32\"),\n                #tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2,width_factor=0.2,fill_mode='nearest',dtype=\"float32\"),\n                tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.2,dtype=\"float32\"),\n                tf.keras.layers.experimental.preprocessing.RandomFlip(dtype=\"float32\")\n            ]\n)\n\ndef apply_data_augment(ds):\n    \n    def f(x,y):\n        #choice = tf.random.uniform(shape=[],minval=0,maxval=len(data_augment_models),dtype=tf.int32).numpy()\n        #data_augment_model = data_augment_models[choice]\n        #print(type(data_augment_model))\n        #if tf.random.uniform([]) < 0.5:\n        return ( data_augment_layers(x), y )\n        #else:\n        #    return (x,y)\n        \n\n    return ds_map_func(f)(ds)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:37.999813Z","iopub.execute_input":"2022-07-26T17:30:38.000860Z","iopub.status.idle":"2022-07-26T17:30:38.044828Z","shell.execute_reply.started":"2022-07-26T17:30:38.000794Z","shell.execute_reply":"2022-07-26T17:30:38.044083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gain training/validation/test datasets","metadata":{}},{"cell_type":"code","source":"#all_ids = lambda ds: next(iter(ds.map(lambda image, label,id: id).batch(NUM_TRAINING_IMAGES))).numpy()\n\nadd_remove_batch_dim = lambda x : tf.squeeze( data_augment_layers( tf.expand_dims(x, axis=0) ), axis=0)\nis_iterable          = lambda x: isinstance(x,collections.abc.Iterable)\n\nbatch_spec         = lambda ds: tf.data.experimental.get_structure(ds)\nis_batched_ds      = lambda ds: (batch_spec(ds))[0].shape[0] == None\nlen_batch_elem     = lambda ds,i: len((batch_spec(ds))[i].shape)\nnb_batch_elem      = lambda ds: len((batch_spec(ds)))\nis_batched_tensor  = lambda t: t.shape[0] == None\n\nremove_id = lambda ds: ds.map(lambda image, label, idnum: [image, label])\n\n\nall_labels = lambda ds: next(iter(ds.map(lambda image, label: label).batch(NUM_TRAINING_IMAGES))).numpy() \n\n\ndef shuffle_batch_prefetch(ds,shuffle_size=SHUFFLE_SIZE,batch_size=BATCH_SIZE,prefetch_size=PREFETCH_SIZE):\n    if shuffle_size is not None:\n        ds = ds.shuffle(shuffle_size)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(prefetch_size)\n    return ds\n\ndef batch_prefetch(ds,batch_size=BATCH_SIZE,prefetch_size=PREFETCH_SIZE):\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(prefetch_size)\n    return ds\n\n#\nget_samples   = lambda ds,n=20,p=1: ds.take(count=n).batch(int(n/p))\nget_one_iter = lambda ds: next(iter(ds))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:38.046331Z","iopub.execute_input":"2022-07-26T17:30:38.046809Z","iopub.status.idle":"2022-07-26T17:30:38.060569Z","shell.execute_reply.started":"2022-07-26T17:30:38.046755Z","shell.execute_reply":"2022-07-26T17:30:38.059776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = get_training_dataset(with_id=True)\nval_ds   = get_validation_dataset()\ntest_ds  = get_test_dataset(ordered=True)\ntrain_sample = remove_id(get_samples(train_ds))\nval_sample   = get_samples(val_ds)\ntest_sample  = get_samples(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:38.061883Z","iopub.execute_input":"2022-07-26T17:30:38.062306Z","iopub.status.idle":"2022-07-26T17:30:38.928373Z","shell.execute_reply.started":"2022-07-26T17:30:38.062261Z","shell.execute_reply":"2022-07-26T17:30:38.927273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Select good quality images","metadata":{}},{"cell_type":"code","source":"\"\"\"\n    Extract prefix (3 first letters) of wordnet classes from list of predictions <preds>\n    <preds> is an iterable of (wordnet class,proba)\n    Returns list of prefix\n\"\"\"\nget_wordnet_class_prefixs = lambda preds : list(map(lambda t: t[0][0:3], preds))\n\ndef get_index(wordnet_classes,s):\n    try:\n        return (wordnet_classes.index(s) + 1)\n    except:\n        return -1\n    \nget_first = lambda word_net_classes: word_net_classes[0]\n\ndef get_wnc_prefix(preds,labels,ids,wnc_prefix='n11'):\n    \"\"\"\n        Map predictions to a dataframe.\n        <preds> is an iterable of (wordnet class,proba)\n        labels is an iterable of label\n        ids labels is an iterable of id\n        Returns a dataframe with the following columns:\n        - wnc_prefix: position of wnc_prefix (-1 if not in the top predictions)\n        - first: wnc_prefix of the first prediction\n        - label: associated label\n        - id: associated id\n    \"\"\"\n    wordnet_class_prefixs =list(map(get_wordnet_class_prefixs, preds))\n    wncs    = list(map(functools.partial(get_index,s=wnc_prefix),wordnet_class_prefixs))\n    firsts  = list(map(get_first,wordnet_class_prefixs))\n    return pd.DataFrame(data={wnc_prefix:wncs,'first':firsts,'label':labels,'id':ids})\n\n#def mk_predicter(model,preprocess):\n#    \"\"\"\n#        Make predicter as a tf.function (executable under a graph) with <model> and <preprocess>\n#    \"\"\"\n#    @tf.function\n#    def predicter(x):\n#        return model(preprocess(x))\n#    return predicter\n\n\"\"\"\n    Make decoder with <decoder> for <top> first predictions  \n\"\"\"\nmk_decoder = lambda decoder,top: functools.partial(decoder,top=top)\n\n# not worrking under tpu\n#def predict_wnc(dist_dataset,predicter,decoder,strategy=STRATEGY):\n#   \"\"\"\n#        Predict wordnet class with <predicter> and <decoder> for data contained in <dist_dataset>\n#        <predicter> is executed under <strategy>\n#        Return list of numpy arrays: [predictions,labels,ids]\n#    \"\"\"\n#    acc = [[],[],[]]\n#    for xs,ys,ids in dist_dataset:\n#        preds = strategy.run(predicter,args=(xs,))\n#        _ = list(map(lambda t: t[0].extend(t[1]), zip(acc,[decoder(preds.numpy()),ys.numpy(),ids.numpy()]) ))\n#    return acc\n\ndef predict_wnc(ds,preprocess,predicter,decoder,strategy=STRATEGY,size=NUM_TRAINING_IMAGES):\n    with strategy.scope():\n        model = tf.keras.Sequential([predicter()])\n    preds = model.predict(batch_prefetch(ds.map(preprocess)))\n    ys = next(iter(ds.map(lambda _,y, id: y ).batch(size))).numpy()\n    ids = next(iter(ds.map(lambda _,y, id: id ).batch(size))).numpy()\n    return [decoder(preds),ys,ids]\n    \ndef count_wnc_prefix(df_wnc,wnc_prefix='n11'):\n    \"\"\"\n      Create a dataframe with the following columns\n      - wnc_prefix: count of wnc_prefix (for label)\n      - total : total count (for label)\n      with label as index\n    \"\"\"\n    groups   = df_wnc.groupby(by=['label',wnc_prefix],as_index=False).count()\n    groups.rename(columns={'first':'subcount'},inplace=True)\n    # total per label\n    totals = groups.groupby(by=['label'],as_index=False)['subcount'].sum()\n    totals.rename(columns={'subcount':'total'},inplace=True)\n    # create total column in groups\n    for l in totals['label'].values:\n        groups.loc[groups['label'] == l,['total']] = totals[totals['label'] == l ]['total'].iloc[0]\n    # labels wo wnc_prefix in the top\n    df1 = groups.loc[(groups[\"subcount\"] == groups[\"total\"]) & (groups[wnc_prefix] == -1),[\"label\",\"subcount\"]]\n    df1[\"subcount\"] = 0\n    # labels with wnc_prefix in the top\n    df2 = (groups[groups[wnc_prefix] != -1].groupby(by=[\"label\"],as_index=False).sum())[[\"label\",\"subcount\"]]\n    # create final dataframe\n    df = pd.concat([df1,df2])\n    df.rename(columns={\"subcount\":wnc_prefix},inplace=True)\n    # create total column in final dataframe\n    for l in totals['label'].values:\n        df.loc[df['label'] == l,['total']] = totals[totals['label'] == l ]['total'].iloc[0]\n    #set label as index\n    #df.set_index('label',inplace=True)\n    return df\n\ndef display_wnc_prefix_counts(wnc_prefix_counts,wnc_prefix='n11'):\n    \"\"\"\n    \"\"\"\n    fig,ax = plt.subplots(figsize=(20,10))\n    total = wnc_prefix_counts[wnc_prefix].sum()\n    empty = len(wnc_prefix_counts[wnc_prefix_counts[wnc_prefix] == 0])\n    title = f'Nb of pictures per label [total: {total} ({wnc_prefix}) - empty classes: {empty}]'\n    _ = wnc_prefix_counts.plot(kind='bar',ax=ax,title=title)\n\ndef get_hash_table(wnc_prefix_df,wnc_prefix='n11'):\n    \"\"\"\n        Create a hash table based on a dataframe of wnc prefixs (obtained by get_wnc_prefix)\n    \"\"\"\n    return tf.lookup.StaticHashTable(\n        tf.lookup.KeyValueTensorInitializer(wnc_prefix_df['id'].values, wnc_prefix_df[wnc_prefix].values),\n        default_value=-1\n    )\n\ndef make_filter(wnc_prefix_df,wnc_prefix='n11'):\n    \"\"\"\n        Create a filter based on <wnc_prefix_df>. Uses a hash table.\n    \"\"\"\n    table = get_hash_table(wnc_prefix_df,wnc_prefix='n11')\n    def f(id):\n        return tf.math.not_equal(table.lookup(id), tf.constant(-1,dtype=tf.int64), name=\"filter\")\n    return f\n\ndef select_img(wnc_prefixes,selective,num_classes= len(CLASSES),wnc_prefix='n11'):\n    wnc_prefixes['selected'] = -1\n    selected = wnc_prefixes.columns.get_loc(\"selected\")\n    selected_labels = set()\n    all_classes = set(range(num_classes))\n    i = 1\n    while(len(all_classes.difference(selected_labels)) > 0):\n        if selective == True:\n            indexes = wnc_prefixes[ ~(wnc_prefixes['label'].isin(selected_labels)) & (wnc_prefixes[wnc_prefix] <= i) & (wnc_prefixes[wnc_prefix] != -1) ].index\n        else:\n            indexes = wnc_prefixes[(wnc_prefixes[wnc_prefix] <= i) & (wnc_prefixes[wnc_prefix] != -1) ].index\n        wnc_prefixes.iloc[indexes,selected] = 1\n        wnc_prefix_counts = count_wnc_prefix(wnc_prefixes[wnc_prefixes['selected'] == 1])\n        selected_labels   = set(wnc_prefix_counts[wnc_prefix_counts[wnc_prefix] != 0]['label'].values)\n        #print(len(set(range(104)).difference(selected_labels)))\n        nb_selected = len(wnc_prefixes[wnc_prefixes['selected'] == 1])\n        #print(f\"selected: {nb_selected}\" )\n        i = i + 1\n    wnc_prefixes.iloc[wnc_prefixes[wnc_prefixes['selected'] == -1].index,wnc_prefixes.columns.get_loc(wnc_prefix)] = -1\n    return nb_selected\n\ndef get_filtered_ds(ds,preprocess,predicter,decoder,top=5,selective=True,strategy=STRATEGY,size=NUM_TRAINING_IMAGES,pred_ds=PRED_DS):\n\"\"\"\n  Create a filtered dataset based on <ds>. Filtering is based on predictions made on <pred_ds> and used <predicter> and <decoder>\n\"\"\"\n    # define decoder\n    top_decoder  = mk_decoder(decoder,top)\n    #do predictions\n    pred_ds = ds if pred_ds is None else pred_ds\n    preds = predict_wnc(pred_ds,preprocess,predicter,top_decoder,strategy,size=size)\n    # based on predictions, select images\n    wnc_prefixes = get_wnc_prefix(*preds)\n    nb_selected = select_img(wnc_prefixes,selective=selective)\n    #create a filter\n    f = make_filter(wnc_prefixes)\n    #filter dataset\n    filtered_ds = ds.filter(lambda x,y,id: f(id))\n    return (remove_id(filtered_ds),wnc_prefixes,nb_selected)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:38.929911Z","iopub.execute_input":"2022-07-26T17:30:38.930803Z","iopub.status.idle":"2022-07-26T17:30:38.960238Z","shell.execute_reply.started":"2022-07-26T17:30:38.930755Z","shell.execute_reply":"2022-07-26T17:30:38.959081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Do filtering","metadata":{}},{"cell_type":"code","source":"predicter    = UT_MODEL\npreprocess   = UT_PREPROCESS\ndecoder      = UT_DECODER\nds = get_training_dataset(with_id=True,ordered=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:30:38.983069Z","iopub.execute_input":"2022-07-26T17:30:38.984342Z","iopub.status.idle":"2022-07-26T17:30:39.158374Z","shell.execute_reply.started":"2022-07-26T17:30:38.984180Z","shell.execute_reply":"2022-07-26T17:30:39.157241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(filtered_ds,wnc_prefixes,nb_selected) = get_filtered_ds(ds,preprocess,predicter,decoder,top=10,strategy=STRATEGY,size=NUM_TRAINING_IMAGES)\nwnc_prefix_counts = count_wnc_prefix(wnc_prefixes)\nwnc_prefix_counts.set_index(keys='label',inplace=True)\ndisplay_wnc_prefix_counts(wnc_prefix_counts)\ndisplay_batch_of_images(get_one_iter(get_samples(filtered_ds)))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:29.345917Z","iopub.execute_input":"2022-07-26T17:33:29.346258Z","iopub.status.idle":"2022-07-26T17:33:37.988528Z","shell.execute_reply.started":"2022-07-26T17:33:29.346214Z","shell.execute_reply":"2022-07-26T17:33:37.987755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(filtered_ds1,wnc_prefixes1,nb_selected1) = get_filtered_ds(ds,preprocess,predicter,decoder,selective=False,top=10,strategy=STRATEGY,size=NUM_TRAINING_IMAGES)\n#wnc_prefix_counts1 = count_wnc_prefix(wnc_prefixes1)\n#wnc_prefix_counts1.set_index(keys='label',inplace=True)\n#display_wnc_prefix_counts(wnc_prefix_counts1)\n#display_batch_of_images(get_one_iter(get_samples(filtered_ds1)))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:37.989582Z","iopub.execute_input":"2022-07-26T17:33:37.989806Z","iopub.status.idle":"2022-07-26T17:33:42.817251Z","shell.execute_reply.started":"2022-07-26T17:33:37.989780Z","shell.execute_reply":"2022-07-26T17:33:42.816126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show the beautiful flowers in training set before with data augmentation","metadata":{}},{"cell_type":"code","source":"display_batch_of_images(get_one_iter(train_sample))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:42.829792Z","iopub.execute_input":"2022-07-26T17:33:42.830143Z","iopub.status.idle":"2022-07-26T17:33:45.158380Z","shell.execute_reply.started":"2022-07-26T17:33:42.830103Z","shell.execute_reply":"2022-07-26T17:33:45.157410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show the beautiful flowers in validation set (wo data augmentation)","metadata":{}},{"cell_type":"code","source":"display_batch_of_images(get_one_iter(val_sample))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:45.159683Z","iopub.execute_input":"2022-07-26T17:33:45.159984Z","iopub.status.idle":"2022-07-26T17:33:48.953949Z","shell.execute_reply.started":"2022-07-26T17:33:45.159952Z","shell.execute_reply":"2022-07-26T17:33:48.953287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show the beautiful flowers in test set (wo data augmentation)","metadata":{}},{"cell_type":"code","source":"display_batch_of_images(get_one_iter(test_sample))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:48.954896Z","iopub.execute_input":"2022-07-26T17:33:48.955249Z","iopub.status.idle":"2022-07-26T17:33:53.350399Z","shell.execute_reply.started":"2022-07-26T17:33:48.955219Z","shell.execute_reply":"2022-07-26T17:33:53.348813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show example augmentation","metadata":{}},{"cell_type":"code","source":"display_batch_of_images(get_one_iter(apply_data_augment(train_sample))) ","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:53.352005Z","iopub.execute_input":"2022-07-26T17:33:53.352372Z","iopub.status.idle":"2022-07-26T17:33:56.633898Z","shell.execute_reply.started":"2022-07-26T17:33:53.352333Z","shell.execute_reply":"2022-07-26T17:33:56.632929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Build the model and make prediction","metadata":{}},{"cell_type":"markdown","source":"### Customize learning rate scheduler and visualize it","metadata":{}},{"cell_type":"code","source":"# Visualization changes in learning rate\ndef plot_lrnfn(lrfn,epochs=EPOCHS):\n    rng = [i for i in range(25 if epochs<25 else epochs)]\n    y = [lrfn(x) for x in rng]\n    plt.figure(figsize=(20,10))\n    plt.plot(rng, y)\n    plt.xticks(rng)\n    plt.grid()\n    print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))\n\n# ramp-up then constant then exponential decay learning rate    \ndef mk_lrfn(strategy=STRATEGY,epoch=EPOCHS,LR_START = 0.00001,LR_MAX = 0.00005,LR_MIN = 0.00001,LR_RAMPUP_EPOCHS = 5,LR_SUSTAIN_EPOCHS = 0,LR_EXP_DECAY = .8):\n    \n    LR_MAX_ = LR_MAX * strategy.num_replicas_in_sync\n    \n    def lrfn(epoch):\n        if epoch < LR_RAMPUP_EPOCHS:\n            lr = (LR_MAX_ - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n            lr = LR_MAX_\n        else:\n            lr = (LR_MAX_ - LR_MIN) * LR_EXP_DECAY ** (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n        return lr\n    \n    return lrfn\n\n# constant lr\nmk_const_lrfn = lambda c : lambda _: c\n#make learning rate callback\nmk_lr_callback = lambda lrfn: tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True) \n\n#make early stopping callback\nmk_early_stopping_cb = lambda fit_patience=5,fit_min_delta=0.002,metric=\"sparse_categorical_accuracy\": tf.keras.callbacks.EarlyStopping(monitor=f'val_{metric}',\n                                                                                                   mode='max',\n                                                                                                   patience=fit_patience,\n                                                                                                   min_delta=fit_min_delta,\n                                                                                                   restore_best_weights=True,\n                                                                                                   verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:34:05.212329Z","iopub.execute_input":"2022-07-26T17:34:05.212631Z","iopub.status.idle":"2022-07-26T17:34:05.228354Z","shell.execute_reply.started":"2022-07-26T17:34:05.212600Z","shell.execute_reply":"2022-07-26T17:34:05.227302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr0 = mk_lrfn()\nlr1 = mk_lrfn(LR_START = 0.00001,LR_MAX = 0.00005,LR_RAMPUP_EPOCHS = 8,LR_SUSTAIN_EPOCHS=3,LR_EXP_DECAY = .95)\nlr2 = mk_const_lrfn(0.00001)\nplot_lrnfn(lr0)\nplot_lrnfn(lr1)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:34:08.908979Z","iopub.execute_input":"2022-07-26T17:34:08.910381Z","iopub.status.idle":"2022-07-26T17:34:11.797319Z","shell.execute_reply.started":"2022-07-26T17:34:08.910325Z","shell.execute_reply":"2022-07-26T17:34:11.796394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compute weight for each class","metadata":{}},{"cell_type":"code","source":"def get_class_weights(ys):\n    \"\"\"\n        ys: numpy array of training etiquettes\n        returns weights to be applied for training\n    \"\"\"\n    classes=np.unique(ys)\n    sk_weights = compute_class_weight('balanced',classes=classes,y=ys)\n    return {i:w for (i,w) in zip(classes,sk_weights)}","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:33:42.819241Z","iopub.execute_input":"2022-07-26T17:33:42.819559Z","iopub.status.idle":"2022-07-26T17:33:42.828146Z","shell.execute_reply.started":"2022-07-26T17:33:42.819525Z","shell.execute_reply":"2022-07-26T17:33:42.827285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build the model","metadata":{}},{"cell_type":"code","source":"def mk_model_builder(tkapp,ishape=[*IMAGE_SIZE,3],num_classes=len(CLASSES)):\n    def model_builder():\n        # fe shall be allocated inside model_builder to benefit from strategy\n        fe = tkapp(\n            include_top=False,\n            weights=\"imagenet\",\n            input_tensor=None,\n            input_shape=ishape\n        )\n\n        fe.trainable = True\n        \n        model = tf.keras.Sequential([\n            tf.keras.Input(name=\"input\",shape=ishape),\n            fe,\n            tf.keras.layers.GlobalAveragePooling2D(),     \n            tf.keras.layers.Dense(num_classes, activation = 'softmax')\n        ])\n        return model\n        \n    return model_builder\n\ndef create_dist_model(model_builder,strategy=STRATEGY):\n    if strategy is not None:\n        with strategy.scope():\n            model = model_builder()\n            model.compile(\n                optimizer=tf.keras.optimizers.Adam(), \n                loss = 'sparse_categorical_crossentropy', \n                metrics = ['sparse_categorical_accuracy']\n            )\n            return model\n    else:\n        model = model_builder()\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(), \n            loss = 'sparse_categorical_crossentropy', \n            metrics = ['sparse_categorical_accuracy']\n        )\n        return model","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:34:14.723290Z","iopub.execute_input":"2022-07-26T17:34:14.723582Z","iopub.status.idle":"2022-07-26T17:34:14.733961Z","shell.execute_reply.started":"2022-07-26T17:34:14.723554Z","shell.execute_reply":"2022-07-26T17:34:14.732953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model","metadata":{}},{"cell_type":"code","source":"def fit_plot(model,train_ds,val_ds,callbacks,weights=None,epochs=EPOCHS,metric=\"sparse_categorical_accuracy\"):\n    \n    history = model.fit(\n        x               = train_ds,\n        #steps_per_epoch = STEPS_PER_EPOCH,\n        epochs          = epochs,\n        callbacks       = callbacks,\n        validation_data = val_ds,\n        class_weight    = weights\n    )\n    \n    # Loss curve\n    plot_train_valid_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)  \n     # Accuracy curve\n    plot_train_valid_curves(history.history['sparse_categorical_accuracy'],history.history[f'val_{metric}'], 'accuracy', 212)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:34:21.881433Z","iopub.execute_input":"2022-07-26T17:34:21.881713Z","iopub.status.idle":"2022-07-26T17:34:21.888753Z","shell.execute_reply.started":"2022-07-26T17:34:21.881686Z","shell.execute_reply":"2022-07-26T17:34:21.887811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First, train the model on augmented good quality images","metadata":{}},{"cell_type":"code","source":"# useful on GPU ?\n#options = tf.data.Options()\n#options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n#expanded_ds = expanded_ds.with_options(options)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:46:44.071421Z","iopub.execute_input":"2022-07-26T16:46:44.071910Z","iopub.status.idle":"2022-07-26T16:46:44.085579Z","shell.execute_reply.started":"2022-07-26T16:46:44.071867Z","shell.execute_reply":"2022-07-26T16:46:44.084445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = get_class_weights(all_labels(filtered_ds))\nmodel_builder =  mk_model_builder(UT_MODEL)\nmodel = create_dist_model(model_builder)\nnum_repeat = int(NUM_TRAINING_IMAGES/nb_selected) - 1\nnum_repeat =  num_repeat if num_repeat > 0 else 1\nfitted_model = fit_plot(model,\n                     train_ds=apply_data_augment(batch_prefetch(filtered_ds.repeat(num_repeat))).shuffle(2048),\n                     #train_ds=shuffle_batch_prefetch(filtered_ds),\n                     val_ds=batch_prefetch(val_ds),\n                     epochs = 10,\n                     callbacks=[mk_lr_callback(lr0),mk_early_stopping_cb(fit_patience=3,fit_min_delta=0.03)],\n                     weights=weights)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T17:34:59.871104Z","iopub.execute_input":"2022-07-26T17:34:59.871648Z","iopub.status.idle":"2022-07-26T17:41:39.778137Z","shell.execute_reply.started":"2022-07-26T17:34:59.871615Z","shell.execute_reply":"2022-07-26T17:41:39.777097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Second, train the model on good quality images","metadata":{}},{"cell_type":"code","source":"#weights1 = get_class_weights(all_labels(filtered_ds1))\nfitted_model = fit_plot(fitted_model,\n                     train_ds=shuffle_batch_prefetch(filtered_ds),\n                     epochs=15,\n                     val_ds=batch_prefetch(val_ds),\n                     callbacks=[mk_lr_callback(lr1),mk_early_stopping_cb(fit_patience=3,fit_min_delta=0.01)],\n                     weights=weights)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:57.560735Z","iopub.execute_input":"2022-07-26T16:55:57.561117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Then, only fit dense layer","metadata":{}},{"cell_type":"code","source":"fitted_model.get_layer(UT_NAME).trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.045143Z","iopub.status.idle":"2022-07-26T16:55:29.045562Z","shell.execute_reply.started":"2022-07-26T16:55:29.045337Z","shell.execute_reply":"2022-07-26T16:55:29.045360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fitted_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.046444Z","iopub.status.idle":"2022-07-26T16:55:29.046770Z","shell.execute_reply.started":"2022-07-26T16:55:29.046606Z","shell.execute_reply":"2022-07-26T16:55:29.046622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds =  get_training_dataset()\nweights = get_class_weights(all_labels(train_ds))\nfitted_model = fit_plot(fitted_model,\n                     train_ds=shuffle_batch_prefetch(train_ds),\n                     val_ds=batch_prefetch(val_ds),\n                     callbacks=[mk_lr_callback(lr2),mk_early_stopping_cb(fit_patience=3,fit_min_delta=0.0005)],\n                     weights=weights)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.047979Z","iopub.status.idle":"2022-07-26T16:55:29.048286Z","shell.execute_reply.started":"2022-07-26T16:55:29.048125Z","shell.execute_reply":"2022-07-26T16:55:29.048141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check model's performance on validation set","metadata":{}},{"cell_type":"code","source":"cmdataset =  batch_prefetch(get_validation_dataset(ordered=True))\n\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch() \n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()  # Get everything as one batch\ncm_probabilities = fitted_model.predict(images_ds)  # The probability that each image is of each class\ncm_predictions = np.argmax(cm_probabilities.astype(np.float32), axis = -1)  # The class of the largest probability is what we need\n\nprint(\"Correct labels: \", cm_correct_labels.shape, cm_correct_labels)\nprint(\"Predicted labels: \", cm_predictions.shape, cm_predictions)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.049065Z","iopub.status.idle":"2022-07-26T16:55:29.049409Z","shell.execute_reply.started":"2022-07-26T16:55:29.049206Z","shell.execute_reply":"2022-07-26T16:55:29.049221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Draw the confusion matrix, compute F1 score, precision, and recall","metadata":{}},{"cell_type":"code","source":"#display_n_images_with_predictions(images_ds.unbatch(),cm_predictions,cm_correct_labels,n=9)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.050376Z","iopub.status.idle":"2022-07-26T16:55:29.050681Z","shell.execute_reply.started":"2022-07-26T16:55:29.050520Z","shell.execute_reply":"2022-07-26T16:55:29.050534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels = range(len(CLASSES)))\nscore = f1_score(cm_correct_labels, cm_predictions, labels = range(len(CLASSES)), average = 'macro')\nprecision = precision_score(cm_correct_labels, cm_predictions, labels = range(len(CLASSES)), average = 'macro')\nrecall = recall_score(cm_correct_labels, cm_predictions, labels = range(len(CLASSES)), average = 'macro')\ncmat = (cmat.T / cmat.sum(axis = 1)).T\ndisplay_confusion_matrix(cmat, score, precision, recall)\nprint('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.051739Z","iopub.status.idle":"2022-07-26T16:55:29.052050Z","shell.execute_reply.started":"2022-07-26T16:55:29.051887Z","shell.execute_reply":"2022-07-26T16:55:29.051902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make prediction","metadata":{}},{"cell_type":"code","source":"def make_prediction(model,test_ds):\n    \n    test_images_ds = test_ds.map(lambda image, idnum: image)\n    probabilities = model.predict(test_images_ds)  # Compute the probability that each image is of each class\n    predictions = np.argmax(probabilities.astype(np.float32), axis = -1)  # Use the one with largest probability as the predicted class\n    #print(predictions)\n\n    # Generate submission file, remember to name it by \"submission.csv\"\n    test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n    test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n    test = pd.DataFrame({\"id\": test_ids, \"label\": predictions})\n    \n    #print(test.head)\n    test.to_csv(\"submission.csv\",index = False)\n    print(\"done\")\n    \nmake_prediction(fitted_model,batch_prefetch(test_ds))","metadata":{"execution":{"iopub.status.busy":"2022-07-26T16:55:29.053002Z","iopub.status.idle":"2022-07-26T16:55:29.053302Z","shell.execute_reply.started":"2022-07-26T16:55:29.053148Z","shell.execute_reply":"2022-07-26T16:55:29.053163Z"},"trusted":true},"execution_count":null,"outputs":[]}]}